import pandas as pd
import torch
import torch.nn as nn
from sklearn.preprocessing import StandardScaler
import torch.quantization
import joblib
import numpy as np
import time
import os
from django.conf import settings


# ----------------------------------------------------
# 1. –¢–û–ß–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ò–ó –†–ê–ë–û–ß–ï–ì–û –ö–û–î–ê
# ----------------------------------------------------

class ResidualBlock(nn.Module):
    """–ë–ª–æ–∫ —Å –æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Å–≤—è–∑—å—é (ResNet)"""

    def __init__(self, dim):
        super().__init__()
        self.linear = nn.Linear(dim, dim)
        self.relu = nn.ReLU()

    def forward(self, x):
        residual = self.relu(self.linear(x))
        return residual + x


class PriceNet(nn.Module):
    def __init__(self, input_dim, hidden_dim=64, num_recommendations=3):
        super().__init__()

        # SHARED BODY —Å RESIDUAL BLOCKS
        self.shared_body = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            ResidualBlock(hidden_dim),
            ResidualBlock(hidden_dim),
        )

        # –£–ì–õ–£–ë–õ–ï–ù–ù–´–ï –ì–û–õ–û–í–´
        self.price_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, num_recommendations)
        )

        self.prob_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, num_recommendations)
        )

        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –ø–æ—Ç–µ—Ä—å
        self.log_price_variance = nn.Parameter(torch.zeros(1), requires_grad=True)
        self.log_prob_variance = nn.Parameter(torch.zeros(1), requires_grad=True)

    def forward(self, x):
        shared_out = self.shared_body(x)
        price_raw = self.price_head(shared_out)
        price = 0.8 + 0.7 * torch.sigmoid(price_raw)
        prob_raw = self.prob_head(shared_out)
        return price, prob_raw


# ----------------------------------------------------
# 2. –ö–û–ù–°–¢–ê–ù–¢–´ –ò–ó –†–ê–ë–û–ß–ï–ì–û –ö–û–î–ê
# ----------------------------------------------------

# –í–∞–∂–µ–Ω –ø–æ—Ä—è–¥–æ–∫! –î–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –ø–æ—Ä—è–¥–∫–æ–º –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.
PRICE_NET_FEATURES = [
    "price_start_local", "distance_in_meters", "duration_in_seconds",
    "pickup_in_meters", "pickup_in_seconds", "driver_rating",
    "waiting_time_sec", "hour_sin", "hour_cos",
    "day_of_week", "price_anomaly", "user_rating"  # ‚Üê 12 –ü–†–ò–ó–ù–ê–ö–û–í!
]

WAITING_TIME_MODEL_FEATURES = [
    "distance_in_meters", "duration_in_seconds", "hour_sin",
    "hour_cos", "day_of_week", "pickup_in_meters",
]

BASE_MODEL_FEATURES = ["distance_in_meters", "duration_in_seconds"]


# ----------------------------------------------------
# 3. –ö–õ–ê–°–° –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø (–° –ü–†–ê–í–ò–õ–¨–ù–´–ú–ò –ü–£–¢–Ø–ú–ò)
# ----------------------------------------------------

class PricePredictor:
    def __init__(self):
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.model = None
        self.scaler = None
        self.waiting_time_model = None
        self.base_model = None

        # –ò–°–ü–û–õ–¨–ó–£–ï–ú –¢–û–ß–ù–´–ô –°–ü–ò–°–û–ö –ü–†–ò–ó–ù–ê–ö–û–í –ò–ó –†–ê–ë–û–ß–ï–ì–û –ö–û–î–ê
        self.features = PRICE_NET_FEATURES  # 12 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!
        self.wt_features = WAITING_TIME_MODEL_FEATURES
        self.base_features = BASE_MODEL_FEATURES

        self._load_all_models()

    def _get_path(self, filename):
        return os.path.join(self.base_dir, filename)

    def _load_all_models(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤—â–∏–∫"""
        try:
            # --- –ó–∞–≥—Ä—É–∑–∫–∞ PriceNet –∏ Scaler ---
            MODEL_PATH = self._get_path('pricenet_model.pth')
            SCALER_PATH = self._get_path('scaler.pkl')

            print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑: {self.base_dir}")
            print(f"üîç –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏: {MODEL_PATH}")
            print(f"üîç –ü–æ–∏—Å–∫ scaler: {SCALER_PATH}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
            if not os.path.exists(MODEL_PATH):
                raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL_PATH}")
            if not os.path.exists(SCALER_PATH):
                raise FileNotFoundError(f"–§–∞–π–ª scaler –Ω–µ –Ω–∞–π–¥–µ–Ω: {SCALER_PATH}")

            # –°–û–ó–î–ê–ï–ú –ú–û–î–ï–õ–¨ –° –ü–†–ê–í–ò–õ–¨–ù–´–ú –ö–û–õ–ò–ß–ï–°–¢–í–û–ú –ü–†–ò–ó–ù–ê–ö–û–í
            input_dim = len(self.features)  # 12 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!
            model_fp32 = PriceNet(input_dim=input_dim)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π variance –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            state_dict = torch.load(MODEL_PATH, map_location='cpu')

            # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã variance –µ—Å–ª–∏ –æ–Ω–∏ –º–µ—à–∞—é—Ç
            keys_to_remove = []
            for key in state_dict.keys():
                if 'variance' in key:
                    keys_to_remove.append(key)

            for key in keys_to_remove:
                del state_dict[key]
                print(f"‚ö†–£–¥–∞–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä: {key}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º state_dict (strict=False –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –ª–∏—à–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
            model_fp32.load_state_dict(state_dict, strict=False)
            model_fp32.eval()

            self.model = torch.quantization.quantize_dynamic(
                model_fp32, {nn.Linear}, dtype=torch.qint8
            )
            print(f"PriceNet –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {input_dim}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º scaler
            self.scaler = joblib.load(SCALER_PATH)
            print(f"–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤—â–∏–∫ –∑–∞–≥—Ä—É–∂–µ–Ω.")

            # --- –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π ---
            WAITING_TIME_MODEL_PATH = self._get_path('waiting_time_model.pkl')
            BASE_MODEL_PATH = self._get_path('base_model.pkl')

            if os.path.exists(WAITING_TIME_MODEL_PATH):
                self.waiting_time_model = joblib.load(WAITING_TIME_MODEL_PATH)
                print(f"–ú–æ–¥–µ–ª—å –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            else:
                print(f"–ú–æ–¥–µ–ª—å –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

            if os.path.exists(BASE_MODEL_PATH):
                self.base_model = joblib.load(BASE_MODEL_PATH)
                print(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            else:
                print(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

            print("–í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            raise

    def _engineer_features(self, order_data):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∏–Ω–∂–µ–Ω–µ—Ä–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (12 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)"""
        # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        order_dt = pd.to_datetime(order_data.get('order_timestamp', pd.Timestamp.now()))

        order_data['day_of_week'] = order_dt.dayofweek
        order_data['hour_of_day'] = order_dt.hour
        order_data['hour_sin'] = np.sin(2 * np.pi * order_data['hour_of_day'] / 24)
        order_data['hour_cos'] = np.cos(2 * np.pi * order_data['hour_of_day'] / 24)

        # 2. –î–æ–±–∞–≤–ª—è–µ–º user_rating (–∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–µ—Ç)
        if 'user_rating' not in order_data:
            order_data['user_rating'] = 4.5  # —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # 3. –ü—Ä–æ–≥–Ω–æ–∑ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –µ—Å—Ç—å)
        if self.waiting_time_model is not None:
            time_input_list = [order_data[f] for f in self.wt_features]
            time_sample_np = np.array(time_input_list, dtype=np.float32).reshape(1, -1)
            predicted_waiting_time = self.waiting_time_model.predict(time_sample_np)[0]
            order_data["waiting_time_sec"] = predicted_waiting_time
        else:
            order_data["waiting_time_sec"] = 300  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # 4. –ü—Ä–æ–≥–Ω–æ–∑ –∞–Ω–æ–º–∞–ª–∏–∏ —Ü–µ–Ω—ã (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –µ—Å—Ç—å)
        if self.base_model is not None:
            base_price_input_list = [order_data[f] for f in self.base_features]
            base_price_sample_np = np.array(base_price_input_list, dtype=np.float32).reshape(1, -1)
            predicted_base_price = self.base_model.predict(base_price_sample_np)[0]
        else:
            predicted_base_price = order_data["price_start_local"] * 1.2

        # –†–∞—Å—á–µ—Ç price_anomaly
        price_anomaly = (predicted_base_price - order_data["price_start_local"]) / predicted_base_price
        order_data["price_anomaly"] = price_anomaly

        # 5. –°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ (12 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!)
        input_list = [order_data[f] for f in self.features]
        sample_np = np.array(input_list, dtype=np.float32).reshape(1, -1)

        return sample_np, order_data["waiting_time_sec"], predicted_base_price

    def get_recommendations(self, order_data):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
        start_time = time.time()

        try:
            # 1. –ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            sample_np, predicted_waiting_time, predicted_base_price = self._engineer_features(order_data)

            # 2. –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–ª—è PriceNet
            sample_scaled = self.scaler.transform(sample_np)
            sample = torch.tensor(sample_scaled, dtype=torch.float32)

            # 3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ PriceNet
            with torch.inference_mode():
                price_rel_pred, prob_raw_pred = self.model(sample)

            prob_pred = torch.sigmoid(prob_raw_pred)
            price_pred_real = price_rel_pred * order_data["price_start_local"]

            # 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            sorted_indices = torch.argsort(price_pred_real[0])
            recommendations = []

            info = {
                "processing_time_ms": round((time.time() - start_time) * 1000, 2),
                "predicted_waiting_time_sec": round(predicted_waiting_time, 1),
                "predicted_base_price_rub": round(predicted_base_price, 2),
                "price_anomaly": round(order_data["price_anomaly"], 3),
            }

            for i in sorted_indices:
                price = price_pred_real[0, i].item()
                prob = prob_pred[0, i].item()

                recommendations.append({
                    "price": round(price),
                    "probability": round(prob, 3),
                    "expected_revenue": round(price * prob, 2)
                })

            return recommendations, info

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ get_recommendations: {e}")
            raise


# –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç–∞–Ω—Å predictor —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
try:
    predictor = PricePredictor()
    print("‚úÖ PricePredictor —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PricePredictor: {e}")
    predictor = None


predictor = PricePredictor()